import os
import cv2
import numpy as np
from tqdm import tqdm
from PIL import Image
import matplotlib.pyplot as plt
from IPython.display import display
from skimage.feature import hog, local_binary_pattern
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix, accuracy_score, f1_score
import seaborn as sns

IMAGE_SIZE = (128, 128)
HOG_PARAMS = {
"orientations": 9,
"pixels_per_cell": (8, 8),
"cells_per_block": (2, 2),
"block_norm": "L2-Hys",
"visualize": True
}
LBP_RADIUS = 1
LBP_POINTS = 8 * LBP_RADIUS
LBP_METHOD = "uniform"

def load_image(image_path):
    img =  cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    return img

#load dataset
images = []
labels = []

data_dir =  "./dataset_final/train"
limit =None;
l_map = {
    "0_non-nodule": 0,
    "1_nodule": 1
}

counter = 0
for l in os.listdir(data_dir):
    l_path =  os.path.join(data_dir, l)
    for d in tqdm (os.listdir(l_path), desc=f"load {l}" , total = len(os.listdir(l_path)), mininterval = 1):
        if (limit is not None and counter > limit):
            counter =0
            break;
        counter += 1
        d_path =  os.path.join(l_path, d)
        img = load_image(d_path)
        images.append(img)
        labels.append(l_map[l])

print("shape:",images[0].shape)

def extract_hog(image):
    features, hog_image = hog(
        image,
        orientations=HOG_PARAMS["orientations"],
        pixels_per_cell=HOG_PARAMS["pixels_per_cell"],
        cells_per_block=HOG_PARAMS["cells_per_block"],
        block_norm=HOG_PARAMS["block_norm"],
        visualize=HOG_PARAMS["visualize"]
    )
    return features, hog_image

f , h =  extract_hog(images[5])
print(f.shape)
plt.imshow(Image.fromarray(h*255), cmap="gray")
plt.show()

hog_features =  []
for im in tqdm(images, desc="load hog_features", total =  len(images), mininterval=1):
    features, _ =  extract_hog(im)
    hog_features.append(features)

print("feature shape:", np.array(hog_features).shape)
print("labels shape:", np.array(labels).shape)
X_train, X_test, y_train, y_test = train_test_split(
    hog_features, labels, test_size=0.2, random_state=42
)

pipeline = Pipeline([
    ("scaler", StandardScaler()),
    ("svm", SVC(kernel="rbf", C=1.0, gamma="scale"))
])

pipeline.fit(X_train, y_train)
accuracy = pipeline.score(X_test, y_test)
print(accuracy)

img_test = []
label_test = []
test_dir = "dataset_final/test"
for l in os.listdir(test_dir):
    l_path =  os.path.join(test_dir, l)
    for m in os.listdir(l_path):
        m_path = os.path.join(l_path, m)
        # print(m_path)
        img_test.append(load_image(m_path))
        label_test.append(l_map[l])

X_pred = []
for m in img_test:
    feature, _ = extract_hog(m)
    X_pred.append(feature)

y_pred = pipeline.predict(X_pred)

cm = confusion_matrix(y_pred, label_test)
acc = accuracy_score(y_pred, label_test)
f1 = f1_score(y_pred, label_test, average="weighted")

plt.figure(figsize=(6, 5))

sns.heatmap(
    cm,
    annot=True,
    fmt="d",
    cmap="Blues",
    cbar=False
)

plt.xlabel("Predicted label")
plt.ylabel("True label")
plt.title(f"Confusion Matrix\nAccuracy: {acc:.4f} | F1-score: {f1:.4f}")

plt.tight_layout()
plt.show()
